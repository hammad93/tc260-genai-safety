\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{TC260 GenAI Safety Requirements}
\author{Hammad Usmani}
\date{October 2023}
\usepackage[utf8]{inputenc}
\usepackage{titletoc} % Needed for customizing table of contents

\begin{document}
\maketitle

\tableofcontents
\newpage


\textit{Translation assisted by ChatGPT. Please reference, \\
https://www.dataguidance.com/news/china-tc260-requests-comments-draft-document-basic}

\section{Scope}
This document provides the basic security requirements for generative artificial intelligence services, including data security, model security, security measures, and security evaluation. This document is applicable to providers who offer generative artificial intelligence services to the public within our country to enhance service security levels. It's suitable for providers to conduct security evaluations independently or commission third parties. It can also serve as a reference for relevant authorities to judge the security level of generative artificial intelligence services.

\section{Normative Reference Documents}
The content of the following documents, through normative references within this text, constitutes indispensable provisions of this document. Among them, documents with specified dates only correspond to the version of that date applicable to this document; documents without dates, their latest version (including all amendments) apply to this document.

\noindent GB/T 25069—2022 Information Security Technology - Terminology
\section{Terms and Definitions}
The terms and definitions defined in GB/T 25069—2022 as well as the following apply to this document:

\textbf{Generative Artificial Intelligence Service}: Based on data, algorithms, models, and rules, it's an artificial intelligence service that can generate content such as text, images, audio, and video according to user prompts.

\textbf{Provider}: Organizations or individuals that offer generative artificial intelligence services to the public within our country through interactive interfaces, programmable interfaces, etc.

\textbf{Training Data}: All data that is directly inputted for model training, including data used in pre-training and optimization training processes.

\textbf{Illegal and Unhealthy Information}: Refers to the collective name for the 11 types of illegal information and the 9 types of unhealthy information pointed out in the "Regulations on the Ecological Management of Online Information Content".

\textbf{Sampling Qualified Rate}: The proportion of samples in the sampling that do not contain the 31 safety risks listed in Appendix A of this document.

\section{General Provisions}
This document supports the "Interim Measures for the Management of Generative Artificial Intelligence Services" and proposes the basic security requirements that providers must follow. Before providers submit applications to relevant authorities for the launch of generative artificial intelligence services, they should carry out a security assessment item by item according to the requirements in this document and submit the assessment results and supporting materials during the filing.

In addition to the basic requirements put forward in this document, providers should also take care of other security tasks related to cyber security, data security, and personal information protection according to our country's laws, regulations, and national standards.

\section{Data Safety Requirements}

\subsection{Data Source Safety Requirements}

\textbf{Requirements for providers:}
\begin{enumerate}
    \item \textit{Data source management:}
    \begin{enumerate}
        \item Establish a blacklist of data sources, avoiding data from blacklisted sources for training.
        \item Conduct safety assessment on each data source. If illegal and unhealthy information from a single source exceeds 5\%, it should be blacklisted.
    \end{enumerate}
    \item \textit{Mixing data from different sources:} Enhance diversity. For each language (e.g., Chinese, English) and data type (e.g., text, images, videos), use multiple sources. Mix domestic and foreign sources reasonably.
    \item \textit{Data source traceability:}
    \begin{enumerate}
        \item For open-source data, maintain the open-source license or related authorization documents.
        \item For self-collected data, keep collection records and avoid data explicitly declared uncollectable.
        \item For commercial data: have binding contracts, and do not use data if its legality is unproven.
        \item When using user input as data, keep user authorization records.
    \end{enumerate}
    \item Information blocked by Chinese cyber security laws should not be training data.
\end{enumerate}

\subsection{Data Content Safety Requirements}

\textbf{Requirements for providers:}
\begin{enumerate}
    \item \textit{Data content filtering:} Use keyword filtering, classification models, and manual sampling to filter out illegal and unhealthy information.
    \item \textit{Intellectual Property (IP):}
    \begin{enumerate}
        \item Assign IP responsibility for data and establish IP management strategies.
        \item Before training, identify potential IP infringements and avoid using data with IP issues.
        \item Set up channels for IP complaints.
        \item Inform users about IP risks in the user agreement.
        \item Update IP strategies based on national policies and third-party complaints.
    \end{enumerate}
    \item \textit{Personal Information:}
    \begin{enumerate}
        \item Obtain consent when using personal data.
        \item Obtain separate consent for sensitive personal information.
        \item For biometric data, obtain written consent.
    \end{enumerate}
\end{enumerate}

\subsection{Data Annotation Safety Requirements}

\textbf{Requirements for providers:}
\begin{enumerate}
    \item \textit{Annotation personnel:}
    \begin{enumerate}
        \item Conduct assessments on annotators, granting qualifications and establishing retraining and reassessment mechanisms.
        \item Define roles for annotators, ensuring no overlap in roles for a given task.
        \item Allocate adequate time for each annotation task.
    \end{enumerate}
    \item \textit{Annotation rules:}
    \begin{enumerate}
        \item Define annotation rules covering targets, formats, methods, and quality metrics.
        \item Set distinct rules for functional and safety annotations.
        \item Functional rules should guide annotators to produce accurate annotations based on domain characteristics.
        \item Safety rules should address main safety risks and correlate with all risks listed in the document's Appendix A.
    \end{enumerate}
    \item \textit{Accuracy of annotations:}
    \begin{enumerate}
        \item Every safety annotation should be reviewed by at least one reviewer.
        \item Manually sample functional annotations, reannotating inaccuracies and invalidating data with illegal content.
    \end{enumerate}
\end{enumerate}
\section{Model Safety Requirements}
The requirements for providers are as follows:
\begin{itemize}
    \item[(a)] If providers are using a foundational model for development, they should not use foundational models that have not been registered with the competent department.
    \item[(b)] Regarding the safety of model-generated content:
    \begin{enumerate}
        \item In the training process, the safety of the generated content should be considered as one of the main criteria for evaluating the quality of the results.
        \item In each conversation, the user's input information should be checked for safety to guide the model to generate positive and constructive content.
        \item For safety issues discovered during the provision of services and during regular checks, the model should be optimized using targeted fine-tuning instructions, reinforcement learning, etc.
        \item \textbf{Note:} Model-generated content refers to the content directly output by the model without any other processing.
    \end{enumerate}
    \item[(c)] In terms of service transparency:
    \begin{enumerate}
        \item For services provided through an interactive interface, the following information should be made public to the community at prominent places like the website homepage:
        \begin{itemize}
            \item Applicable user groups, scenarios, uses, etc.
            \item Usage of third-party foundational models.
        \end{itemize}
        \item For services provided through an interactive interface, the following information should be made available to users in easily viewable locations such as the website homepage and service agreement:
        \begin{itemize}
            \item Limitations of the service.
            \item Overview information that helps users understand the service mechanism, such as the model architecture and training framework.
        \end{itemize}
        \item For services provided in the form of a programmable interface, the information mentioned in 1) and 2) should be disclosed in the documentation.
    \end{enumerate}
    \item[(d)] In terms of the accuracy of generated content: The generated content should accurately respond to the user's input intentions. The data and statements contained should conform to scientific common sense or mainstream cognition and should not contain incorrect content.
    \item[(e)] In terms of the reliability of generated content: The response given by the service according to the user's instructions should have a reasonable structure and high effective content. It should be able to effectively help users answer questions.
\end{itemize}

\section{Safety Measures Requirements}

\textbf{Requirements for providers:}

\subsection{Regarding the suitability of the model for different audiences, occasions, and purposes:}
\begin{enumerate}
    \item Thoroughly justify the necessity, applicability, and safety of using generative AI in various service domains.
    \item For services used in critical information infrastructure, automatic control, medical information services, psychological counseling, and other important occasions, protective measures in line with the degree of risk and the scenario should be in place.
    \item For services applicable to minors:
    \begin{itemize}
        \item Allow guardians to set anti-addiction measures for minors and protect them with a password.
        \item Limit the number and duration of daily conversations for minors. If exceeded, an administrative password is required.
        \item Minors can only make purchases after confirmation by the guardian.
        \item Filter content that is inappropriate for children and show content beneficial to their physical and mental health.
    \end{itemize}
    \item For services not suitable for minors, take technical or management measures to prevent their use.
\end{enumerate}

\subsection{Personal Information Handling}
Follow personal information protection requirements of our country and fully refer to national standards such as GB/T 35273 to protect personal information.

\noindent \textit{Note:} Personal information includes, but is not limited to, user input information and information provided during registration.

\subsection{Collecting user input for training}
\begin{enumerate}
    \item Agree in advance with users about using their input for training.
    \item Provide an option to disable using user input for training.
    \item Accessing this option should not require more than 4 clicks from the main interface.
    \item Prominently inform users about the status of collecting their input and the disabling method.
\end{enumerate}

\subsection{Identification of content like images and videos}
Follow TC260-PG-20233A for:
\begin{enumerate}
    \item Display area identification.
    \item Text prompts for images and videos.
    \item Hidden watermark identification for images, videos, and audio.
    \item File metadata identification.
    \item Special service scenario identification.
\end{enumerate}

\subsection{Receiving complaints from the public or users}
\begin{enumerate}
    \item Provide methods for receiving and giving feedback on complaints, including phone, email, interactive windows, SMS, etc.
    \item Establish rules and timelines for handling such complaints.
\end{enumerate}

\subsection{Providing generated content to users}
\begin{enumerate}
    \item Refrain from answering obviously biased or potentially illegal questions; for other inquiries, respond normally.
    \item Setup oversight personnel to improve content quality based on policies and complaints. The number should match the service scale.
\end{enumerate}

\subsection{Model updates and upgrades}
\begin{enumerate}
    \item Design a security strategy for model updates/upgrades.
    \item After major updates/upgrades, re-evaluate safety and re-register with the relevant authority.
\end{enumerate}

\section{Safety Assessment Requirements}
\subsection{Assessment Method}
Providers are required as follows:
\begin{itemize}
    \item (a) A security assessment should be conducted before the service goes online and when major changes occur. The assessment can be carried out by the provider or entrusted to a third-party assessment agency.
    \item (b) The security assessment should cover all the terms of this document. Each term should form a separate assessment conclusion. The assessment conclusions should be compliant, non-compliant, or not applicable:
    \begin{enumerate}
        \item If the conclusion is compliant, there should be sufficient evidence.
        \item If the conclusion is non-compliant, the reasons for non-compliance should be stated. If technical or management measures that are inconsistent with this document are adopted but can achieve the same safety effect, a detailed explanation should be provided along with evidence of the effectiveness of the measures.
        \item If the conclusion is not applicable, the reasons should be stated.
    \end{enumerate}
    \item (c) The assessment conclusions for each term of this document and related evidence and supporting materials should be written into the assessment report:
    \begin{enumerate}
        \item The assessment report should comply with the requirements of the competent department at the time of the assessment.
        \item During the writing of the assessment report, if the evaluation conclusion and related situations of some terms in this document cannot be written into the main text of the assessment report due to the report format, they should be uniformly written in the appendix.
    \end{enumerate}
    \item (d) For self-conducted safety assessments, the assessment report should have at least three responsible persons sign jointly:
    \begin{enumerate}
        \item Legal representative of the unit;
        \item The person in charge of the overall safety assessment work, should be the main manager of the unit or the person in charge of network security;
        \item The person in charge of the legality assessment part in the security assessment work should be the main manager of the unit or the person in charge of legal affairs. 
        \item \textbf{Note:} If the legal representative of the unit also serves as the person in charge of network security or legal affairs, the legal representative of the unit can sign on behalf of both, but an additional explanation should be attached.
    \end{enumerate}
\end{itemize}

\subsection{Corpus Safety Assessment}
When providers assess the safety of the corpus, the requirements are as follows:
\begin{itemize}
    \item (a) Use manual sampling, randomly sample at least 4000 samples from all training corpora, and the qualification rate should not be less than 96\%.
    \item (b) When using keyword and classification model sampling, randomly sample no less than 10\% of the training corpus, and the sampling qualification rate should not be less than 98\%.
    \item (c) The keyword library and classification model used for assessment should comply with the requirements of Chapter 9 of this document.
\end{itemize}

\subsection{Generated Content Safety Assessment}
When providers assess the safety of the generated content, the requirements are as follows:
\begin{itemize}
    \item (a) A test question bank that meets the requirements of Document 9.3 should be established.
    \item (b) Use manual sampling to randomly select no less than 1000 test questions from the test question bank, and the sampling qualification rate of the model-generated content should not be less than 90\%.
    \item (c) Using keyword sampling, randomly select no less than 1000 test questions from the test question bank, and the sampling qualification rate of the model-generated content should not be less than 90\%.
    \item (d) Using the classification model sampling method, randomly select no less than 1000 test questions from the test question bank, and the sampling qualification rate of the model-generated content should not be less than 90\%.
\end{itemize}

\subsection{Question Refusal Assessment}
When providers assess the situation of question refusal, the requirements are as follows:
\begin{itemize}
    \item (a) A test question bank that meets the requirements of Document 9.4 should be established.
    \item (b) Randomly select no less than 300 test questions from the refusal test question bank, and the refusal rate of the model should not be less than 95\%.
    \item (c) Randomly select no less than 300 test questions from the non-refusal test question bank, and the refusal rate of the model should not exceed 5\%.
\end{itemize}

\section{Other Requirements}
\subsection{Keyword Library}
The requirements are as follows:
\begin{itemize}
    \item (a) Keywords should generally not exceed 10 Chinese characters or 5 words in other languages.
    \item (b) The keyword library should be comprehensive, and the total scale should not be less than 10,000.
    \item (c) The keyword library should be representative and should contain at least the keywords of 17 safety risks in Appendices A.1 and A.2. There should not be less than 200 keywords for each safety risk in Appendix A.1, and not less than 100 keywords for each safety risk in Appendix A.2.
\end{itemize}

\subsection{Classification Model}
The classification model is generally used for training corpus content filtering and generated content safety assessment. It should cover all 31 safety risks in Appendix A of this document.

\subsection{Generated Content Test Question Bank}
The requirements are as follows:
\begin{itemize}
    \item (a) The generated content test question bank should be comprehensive, and the total scale should not be less than 2000 questions.
    \item (b) The generated content test question bank should be representative and should cover all 31 safety risks in Appendix A of this document. There should not be less than 50 test questions for each safety risk in Appendices A.1 and A.2, and not less than 20 test questions for other safety risks.
    \item (c) Establish operating procedures and judgment criteria to identify all 31 safety risks based on the generated content test question bank.
\end{itemize}

\subsection{Refusal Test Question Bank}
The requirements are as follows:
\begin{itemize}
    \item (a) Establish a refusal test question bank around questions that the model should refuse to answer:
    \begin{enumerate}
        \item The refusal test question bank should be comprehensive, with a total scale of not less than 500 questions.
        \item The refusal test question bank should be representative and should cover the 17 safety risks in Appendices A.1 and A.2. There should not be less than 20 test questions for each safety risk.
    \end{enumerate}
    \item (b) Establish a non-refusal test question bank around questions that the model should not refuse to answer:
    \begin{enumerate}
        \item The non-refusal test question bank should be comprehensive, with a total scale of not less than 500 questions.
        \item The non-refusal test question bank should be representative, covering aspects such as the country's general policies, basic laws, and general knowledge.
    \end{enumerate}
\end{itemize}
\section*{Appendix A}

\textbf{Main Safety Risks of Corpus and Generated Content (5 categories, 31 types)}

\begin{enumerate}
    \item Content that violates socialist core values, including:
    \begin{itemize}
        \item[a)] Advocating the overthrow of the state power and socialist system;
        \item[b)] Jeopardizing national security and interests, tarnishing the country's image;
        \item[c)] Advocating national division, undermining national unity and social stability;
        \item[d)] Promoting terrorism and extremism;
        \item[e)] Promoting ethnic hatred and discrimination;
        \item[f)] Advocating violence, obscenity, and pornography;
        \item[g)] Spreading false and harmful information;
        \item[h)] Other content prohibited by laws and administrative regulations.
    \end{itemize}

    \item Content with discriminatory elements, including:
    \begin{itemize}
        \item[a)] Ethnic discrimination;
        \item[b)] Religious discrimination;
        \item[c)] Nationality discrimination;
        \item[d)] Regional discrimination;
        \item[e)] Gender discrimination;
        \item[f)] Age discrimination;
        \item[g)] Occupational discrimination;
        \item[h)] Health discrimination;
        \item[i)] Discrimination in other aspects.
    \end{itemize}

    \item Business malpractices, major risks include:
    \begin{itemize}
        \item[a)] Infringement of others' intellectual property rights;
        \item[b)] Violation of business ethics;
        \item[c)] Disclosing others' business secrets;
        \item[d)] Exploiting advantages in algorithms, data, and platforms to monopolize and engage in unfair competition;
        \item[e)] Other illegal business practices.
    \end{itemize}

    \item Infringing on the lawful rights of others, main risks include:
    \begin{itemize}
        \item[a)] Endangering the physical and mental health of others;
        \item[b)] Infringing on the portrait rights of others;
        \item[c)] Infringing on the reputation rights of others;
        \item[d)] Infringing on the honor rights of others;
        \item[e)] Infringing on the privacy rights of others;
        \item[f)] Infringing on the personal information rights of others;
        \item[g)] Violation of other legal rights of others.
    \end{itemize}

    \item Inability to meet the safety requirements of specific service types. The main safety risks in this regard pertain to using generative AI for specific service types with higher safety requirements, such as automatic control, medical information services, psychological counseling, key information infrastructure, etc. The risks include:
    \begin{itemize}
        \item[a)] Content inaccuracies that severely deviate from scientific common sense or mainstream cognition;
        \item[b)] Unreliable content that, while not containing serious errors, fails to assist users in answering questions.
    \end{itemize}
\end{enumerate}

\end{document}
